{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACT \n",
    "## Fetching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load in modules we will need \"\"\"\n",
    "import os\n",
    "import gc\n",
    "import pymssql\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime as dt\n",
    "load_dotenv()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"Reading\" from Bronze Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve all the csv file names from a given path\n",
    "\n",
    "Parameters: \n",
    "path (string)- Path we are looking through\n",
    "\n",
    "Returns: a list of .csv files\n",
    "\"\"\"\n",
    "def grab_files(path: str) -> list:\n",
    "    return [file for file in os.listdir(path) if file.endswith(\".csv\")]\n",
    "\n",
    "\"\"\"\n",
    "Creates DataFrames for all data of a specific entity in \"Bronze layer\"\n",
    "\n",
    "Parameters: \n",
    "path (string) - The \"container\" for the data \n",
    "\n",
    "Returns: a list of .csv files\n",
    "\"\"\"\n",
    "def gen_dfs(ospath = 'BRONZE_LAYER', path:str =''):    \n",
    "    dfs = []\n",
    "    try:\n",
    "        data_dir = f'{os.environ[ospath]}{path + \"/\" if path != \"\" else path}'\n",
    "        files = grab_files(data_dir)\n",
    "        for f in files:\n",
    "            df = pd.read_csv(data_dir+f)\n",
    "            df.name = f.split('__')[1]\n",
    "            dfs.append(df)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error with pathing\")\n",
    "    except:\n",
    "        print('Error Occurred while extracting data from the file')\n",
    "    return dfs        #create the dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM\n",
    "## Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Will Attempt to Drop all declared columns from a DataFrame\n",
    "\n",
    "Parameters: \n",
    "df - a singular Data Frame\n",
    "cols - a list of strings containing column attributes to be dropped\n",
    "\n",
    "Returns: Nothing\n",
    "\"\"\"\n",
    "def drop_dfcols(df, cols:list):\n",
    "    try:\n",
    "        df.drop(columns = cols, inplace = True)\n",
    "    except KeyError:\n",
    "        print(f'fail to remove{cols}')\n",
    "\n",
    "\"\"\"\n",
    "Will Attempt to Drop all declared columns from a List of DataFrame\n",
    "\n",
    "Parameters: \n",
    "df - a List of Data Frame\n",
    "cols - a list of strings containing column attributes to be dropped \n",
    "\n",
    "Returns: Nothing\n",
    "\"\"\"\n",
    "def drop_dfs_col(dfs, cols: list):\n",
    "    try:\n",
    "        for df in dfs:\n",
    "            drop_dfcols(df,cols) \n",
    "    except KeyError:\n",
    "        print('no columns left')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remove duplicate records from the DataFrame\n",
    "\"\"\"\n",
    "def rm_dupe(df):\n",
    "    df.drop_duplicates(inplace= True)\n",
    "\n",
    "\"\"\"\n",
    "Drops the columns that have null vals\n",
    "or we fill them will default values if we want\n",
    "\"\"\"\n",
    "def rm_nulls(df, col, default_val = None):\n",
    "    if default_val:\n",
    "        df[col].fillna(default_val, inplace = True)\n",
    "    else:\n",
    "        df.dropna(subset =[col], inplace= True) \n",
    "\n",
    "\"\"\"\n",
    "Checks to see if any column of a DataFrame contains Nulls\n",
    "-best to do this after dropping useless columns [faster]\n",
    "\"\"\"\n",
    "def cols_with_null(df):\n",
    "    has_null = []\n",
    "    for col in df.columns:\n",
    "        print(f'{col} : {df[col].isnull().values.any()}')\n",
    "        if df[col].isnull().values.any():\n",
    "            has_null.append(col)\n",
    "    return has_null\n",
    "\n",
    "\"\"\"\n",
    "Parameters:\n",
    "dfs: List of DataFrames \n",
    "Return: Merged DataFrames \n",
    "\"\"\"\n",
    "def merge_dfs(dfs: list):\n",
    "    name_attr = dfs[0].name if hasattr(dfs[0], \"name\") else None\n",
    "    dfs = pd.concat(dfs, ignore_index=True)        #put all the data into one table\n",
    "    if name_attr:\n",
    "        dfs.name = name_attr\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checks to see if a val is of type : etype\n",
    "\n",
    "Parameters:\n",
    "etype: Type \n",
    "\n",
    "Returns:\n",
    "Boolean if it is that type\n",
    "\"\"\"\n",
    "def is_type(val,  etype):\n",
    "    try:\n",
    "        etype(val)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "    \n",
    "\"\"\"\n",
    "Removes all the records that have an invalid type\n",
    "\n",
    "Parameters:\n",
    "header_df : DataFrame\n",
    "col : column name to check\n",
    "etype: Type \n",
    "\n",
    "Returns:\n",
    "DataFrame with records that have valid type\n",
    "\"\"\"\n",
    "def rm_inval_type(df, col, etype):\n",
    "    name_attr = df.name if hasattr(df, \"name\") else None\n",
    "    df = df[df[col].apply(lambda val: is_type(val,etype))]\n",
    "    if name_attr:\n",
    "        df.name = name_attr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Removes outliers (using Interquartile range) from a given column\n",
    "Parameters:\n",
    "df: DataFrame\n",
    "col: column to check for outliers\n",
    "Returns: DataFrame with outliers removed\n",
    "\"\"\"\n",
    "def IQR_outlier(df, col: str):\n",
    "    name_attr = df.name if hasattr(df, \"name\") else None\n",
    "    Q1 = df[col].quantile(0.25)   \n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # non_outliers = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    df_rm_outliers = df[~((df[col] < lower_bound) | (df[col] > upper_bound))]\n",
    "    if name_attr:\n",
    "        df_rm_outliers.name = name_attr\n",
    "    return df_rm_outliers\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Removes outliers (using Z-score) from a given column\n",
    "Parameters:\n",
    "df: DataFrame\n",
    "col: column to check for outliers\n",
    "deviance: outlier bounds\n",
    "Returns: DataFrame with outliers removed\n",
    "\"\"\"\n",
    "def zscore(df, col:str, deviance:int):\n",
    "    col_mean = df[col].mean()\n",
    "    col_std = df[col].std()\n",
    "    return df[abs((df[col] - col_mean)/ col_std) <= deviance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD\n",
    "### Save into Currated layer [Silver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Will file \"modded_{filename}.csv\"\n",
    "in curated-layer directory.\n",
    "If path does not exist, will create it for you.\n",
    "\n",
    "Parameters: \n",
    "df - a Data Frame\n",
    "\n",
    "Returns: Nothing\n",
    "\"\"\"\n",
    "def df2csv(df):\n",
    "    year = df.name[-4:]\n",
    "    type = df.name[:-5]\n",
    "    path = f'../data_set/CBP_AMS/curated-layer/{year}/{type}/'          \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    df.to_csv(path + f'modded_{df.name}.csv', sep='|' , index=False) \n",
    "\n",
    "    \"\"\"\n",
    "Will file \"modded_{filename}.parquet\"\n",
    "in curated-layer directory.\n",
    "If path does not exist, will create it for you.\n",
    "\n",
    "Parameters: \n",
    "df - a Data Frame\n",
    "\n",
    "Returns: Nothing\n",
    "\"\"\"\n",
    "def df2parquet(df):\n",
    "    year = df.name[-4:]\n",
    "    type = df.name[:-5]\n",
    "    path = f'../data_set/CBP_AMS/curated-layer/{year}/{type}/'          \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    df.to_parquet(path + f'modded_{df.name}.parquet', engine='pyarrow',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Current Use Case : We can reduce data overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_billgen = ['house_bol_number','sub_house_bol_number', 'bill_type_code',\n",
    "              'manifest_number', 'trade_update_date', 'run_date']\n",
    "\n",
    "rm_container = ['seal_number_1', 'seal_number_2',\n",
    "       'equipment_description_code','container_type', 'load_status']\n",
    "\n",
    "rm_header  = ['carrier_code', 'vessel_country_code', 'vessel_name',\n",
    "       'foreign_port_of_lading_qualifier', 'manifest_quantity', 'manifest_unit', \n",
    "       'measurement', 'measurement_unit', 'record_status_indicator',\n",
    "       'place_of_receipt', 'port_of_destination', 'foreign_port_of_destination_qualifier', \n",
    "       'foreign_port_of_destination', 'conveyance_id_qualifier', 'conveyance_id', \n",
    "       'in_bond_entry_type', 'mode_of_transportation', 'secondary_notify_party_1',\n",
    "       'secondary_notify_party_2', 'secondary_notify_party_3', 'secondary_notify_party_4', \n",
    "       'secondary_notify_party_5', 'secondary_notify_party_6', 'secondary_notify_party_7',\n",
    "       'secondary_notify_party_8', 'secondary_notify_party_9', 'secondary_notify_party_10']\n",
    "\n",
    "rm_tariff = ['description_sequence_number','harmonized_number', 'harmonized_weight_unit','harmonized_weight']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------HEADER--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning Header Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the weight column to a universal weight unit measurement\n",
    "\n",
    "Parameters:\n",
    "header_df: DataFrame\n",
    "\n",
    "Returns:\n",
    "None\n",
    "\"\"\"\n",
    "def universal_unit(header_df):\n",
    "    unit_weight = {\n",
    "        'Kilograms': 1.0,\n",
    "        'Pounds': 0.453592, \n",
    "        'Metric Ton': 1000.0, \n",
    "        'Long Ton': 1016.04691, \n",
    "        'Measurement Ton': 1.01604691\n",
    "    }\n",
    "    # Convert weight to kg based on weight_unit\n",
    "    for unit, scale in unit_weight.items():\n",
    "        header_df.loc[header_df['weight_unit'] == unit, 'weight'] *= scale\n",
    "        header_df['weight_unit'] = 'Kilograms'\n",
    "\n",
    "\n",
    "def is_date(val):\n",
    "    try:\n",
    "        dt.strptime(val, '%Y-%m-%d')\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def rm_inval_date(df,col):\n",
    "    name_attr = df.name if hasattr(df, \"name\") else None\n",
    "    df = df[df[col].apply(is_date)]\n",
    "    if name_attr:\n",
    "        df.name = name_attr\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "removes the records that have dates that are not in the scope of this year\n",
    "\"\"\"\n",
    "def date_outlier(df):\n",
    "    name_attr = df.name if hasattr(df, \"name\") else None\n",
    "    year = int(df.name[-4:])\n",
    "    df['estimated_arrival_date'] = pd.to_datetime(df['estimated_arrival_date'], format='%Y-%m-%d')\n",
    "    df['actual_arrival_date'] = pd.to_datetime(df['actual_arrival_date'], format='%Y-%m-%d')\n",
    "    df = df[df['actual_arrival_date'].dt.year <= year]   # we are not in the future!!!\n",
    "    df = df[(abs(df['estimated_arrival_date'].dt.year - year) <= 5)]\n",
    "    df = df[(abs(df['actual_arrival_date'].dt.year - year) <= 5)]\n",
    "    if name_attr:\n",
    "        df.name = name_attr\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in HEADER Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currated layer only requires : container |  header  |  tariff   |   billgen   \n",
    "dfs = gen_dfs(path='header')\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we will not be using\n",
    "drop_dfs_col(dfs, rm_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes into one \n",
    "dfs = merge_dfs(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate records\n",
    "rm_dupe(dfs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removal of any irregular data in the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure there are no null values ðŸ˜€\n",
    "for col in cols_with_null(dfs):\n",
    "    rm_nulls(dfs, col)\n",
    "# Header does not need to deal with any Nulls ðŸŽ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type of weight columns \n",
    "dfs = rm_inval_type(dfs, 'weight', int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = rm_inval_type(dfs, 'port_of_unlading', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = rm_inval_type(dfs, 'foreign_port_of_lading', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = rm_inval_type(dfs, 'weight_unit', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any invalid date in this col\n",
    "dfs = rm_inval_date(dfs, 'estimated_arrival_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any invalid date in this col\n",
    "dfs = rm_inval_date(dfs, 'actual_arrival_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove out the Outliers\n",
    "dfs = IQR_outlier(dfs, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any date outliers \n",
    "dfs = date_outlier(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the weight unit to a singular unit ( Kilogram )\n",
    "universal_unit(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned up Header Data -> Store into \"Silver Layer\" \n",
    "df2csv(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------BILL GEN--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>master_bol_number</th>\n",
       "      <th>house_bol_number</th>\n",
       "      <th>sub_house_bol_number</th>\n",
       "      <th>voyage_number</th>\n",
       "      <th>bill_type_code</th>\n",
       "      <th>manifest_number</th>\n",
       "      <th>trade_update_date</th>\n",
       "      <th>run_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201901010</td>\n",
       "      <td>OOLU2593478240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>091E</td>\n",
       "      <td>Master Bill</td>\n",
       "      <td>588.000</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201901011</td>\n",
       "      <td>MOLU13903770302</td>\n",
       "      <td>AEHSSKOL01019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>033E</td>\n",
       "      <td>House Bill</td>\n",
       "      <td>9916.000</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901012</td>\n",
       "      <td>APLU711051802</td>\n",
       "      <td>EXDO616620226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00025</td>\n",
       "      <td>House Bill</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2018-03-13</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201901013</td>\n",
       "      <td>APLU711051813</td>\n",
       "      <td>EXDO616620230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00025</td>\n",
       "      <td>House Bill</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901014</td>\n",
       "      <td>APLU711051920</td>\n",
       "      <td>EXDO616620247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00025</td>\n",
       "      <td>House Bill</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>2019070888895</td>\n",
       "      <td>HLCUTYO190515489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001E</td>\n",
       "      <td>Simple BOL FROB</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>2019070888896</td>\n",
       "      <td>HLCUTYO190517770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001E</td>\n",
       "      <td>Simple BOL FROB</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>2019070888897</td>\n",
       "      <td>HLCUTYO190529030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001E</td>\n",
       "      <td>Simple BOL FROB</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>2019070888898</td>\n",
       "      <td>HLCUTYO190601508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001E</td>\n",
       "      <td>Simple BOL FROB</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2019070888899</td>\n",
       "      <td>HLCUTYO190605966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001E</td>\n",
       "      <td>Simple BOL FROB</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>2019-07-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            identifier master_bol_number house_bol_number  \\\n",
       "0            201901010    OOLU2593478240              NaN   \n",
       "1            201901011   MOLU13903770302    AEHSSKOL01019   \n",
       "2            201901012     APLU711051802    EXDO616620226   \n",
       "3            201901013     APLU711051813    EXDO616620230   \n",
       "4            201901014     APLU711051920    EXDO616620247   \n",
       "...                ...               ...              ...   \n",
       "9999995  2019070888895  HLCUTYO190515489              NaN   \n",
       "9999996  2019070888896  HLCUTYO190517770              NaN   \n",
       "9999997  2019070888897  HLCUTYO190529030              NaN   \n",
       "9999998  2019070888898  HLCUTYO190601508              NaN   \n",
       "9999999  2019070888899  HLCUTYO190605966              NaN   \n",
       "\n",
       "         sub_house_bol_number voyage_number   bill_type_code  manifest_number  \\\n",
       "0                         NaN          091E      Master Bill          588.000   \n",
       "1                         NaN          033E       House Bill         9916.000   \n",
       "2                         NaN         00025       House Bill            1.000   \n",
       "3                         NaN         00025       House Bill            1.000   \n",
       "4                         NaN         00025       House Bill            1.000   \n",
       "...                       ...           ...              ...              ...   \n",
       "9999995                   NaN          001E  Simple BOL FROB            1.000   \n",
       "9999996                   NaN          001E  Simple BOL FROB            1.000   \n",
       "9999997                   NaN          001E  Simple BOL FROB            1.000   \n",
       "9999998                   NaN          001E  Simple BOL FROB            1.000   \n",
       "9999999                   NaN          001E  Simple BOL FROB            1.000   \n",
       "\n",
       "        trade_update_date    run_date  \n",
       "0              2018-12-31  2019-01-01  \n",
       "1              2018-12-31  2019-01-01  \n",
       "2              2018-03-13  2019-01-01  \n",
       "3              2018-03-06  2019-01-01  \n",
       "4              2018-03-19  2019-01-01  \n",
       "...                   ...         ...  \n",
       "9999995        2019-06-25  2019-07-08  \n",
       "9999996        2019-06-25  2019-07-08  \n",
       "9999997        2019-06-25  2019-07-08  \n",
       "9999998        2019-06-25  2019-07-08  \n",
       "9999999        2019-06-25  2019-07-08  \n",
       "\n",
       "[10000000 rows x 9 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currated layer only requires : container |  header  |  tariff   |   billgen   \n",
    "dfs = gen_dfs(path='billgen')\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we will not be using\n",
    "drop_dfs_col(dfs, rm_billgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes into one  \n",
    "dfs = merge_dfs(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate records  \n",
    "rm_dupe(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifier : False\n",
      "master_bol_number : False\n",
      "voyage_number : False\n"
     ]
    }
   ],
   "source": [
    "# remove any null values\n",
    "for col in cols_with_null(dfs):\n",
    "    rm_nulls(dfs, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned up Bill Gen Data -> Store into \"Silver Layer\" \n",
    "df2csv(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------CONTAINER--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_box_outlier(df):\n",
    "    name_attr = df.name if hasattr(df, \"name\") else None\n",
    "    df = df[(df['container_length'] != 0) & (df['container_width'] != 0) & (df['container_height'] != 0)]\n",
    "    if name_attr:\n",
    "        df.name = name_attr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>container_number</th>\n",
       "      <th>seal_number_1</th>\n",
       "      <th>seal_number_2</th>\n",
       "      <th>equipment_description_code</th>\n",
       "      <th>container_length</th>\n",
       "      <th>container_height</th>\n",
       "      <th>container_width</th>\n",
       "      <th>container_type</th>\n",
       "      <th>load_status</th>\n",
       "      <th>type_of_service</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201901010</td>\n",
       "      <td>OOCU6796874</td>\n",
       "      <td>OOLDZP0928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Container</td>\n",
       "      <td>4000</td>\n",
       "      <td>906</td>\n",
       "      <td>802</td>\n",
       "      <td>4EB0</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Container Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201901011</td>\n",
       "      <td>FCIU5657370</td>\n",
       "      <td>376646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Container</td>\n",
       "      <td>2000</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>2200</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Container Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201901012</td>\n",
       "      <td>CMAU4612647</td>\n",
       "      <td>G0137453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Container</td>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>45G0</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Container Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201901012</td>\n",
       "      <td>TGHU9897308</td>\n",
       "      <td>G0137517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Container</td>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>45G0</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Container Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201901012</td>\n",
       "      <td>SEGU4018985</td>\n",
       "      <td>G0137448</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Container</td>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>45G0</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Container Yard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999995</th>\n",
       "      <td>2019043057226</td>\n",
       "      <td>OOLU8979700</td>\n",
       "      <td>7280342</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G1</td>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>45G1</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>House to House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999996</th>\n",
       "      <td>2019043057226</td>\n",
       "      <td>OOLU9568200</td>\n",
       "      <td>7280341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G1</td>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>45G1</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>House to House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999997</th>\n",
       "      <td>2019043057227</td>\n",
       "      <td>OOLU7866680</td>\n",
       "      <td>OOLESU2963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G1</td>\n",
       "      <td>4000</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>42G1</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>House to House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999998</th>\n",
       "      <td>2019043057227</td>\n",
       "      <td>OOLU7640434</td>\n",
       "      <td>OOLESU2955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G1</td>\n",
       "      <td>4000</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>42G1</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>House to House</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999999</th>\n",
       "      <td>2019043057228</td>\n",
       "      <td>KKTU8114548</td>\n",
       "      <td>TW070212A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Openings at one end or both ends.</td>\n",
       "      <td>2000</td>\n",
       "      <td>806</td>\n",
       "      <td>802</td>\n",
       "      <td>2CG0</td>\n",
       "      <td>Loaded</td>\n",
       "      <td>Pier to House</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            identifier container_number seal_number_1 seal_number_2  \\\n",
       "0            201901010      OOCU6796874    OOLDZP0928           NaN   \n",
       "1            201901011      FCIU5657370        376646           NaN   \n",
       "2            201901012      CMAU4612647      G0137453           NaN   \n",
       "3            201901012      TGHU9897308      G0137517           NaN   \n",
       "4            201901012      SEGU4018985      G0137448           NaN   \n",
       "...                ...              ...           ...           ...   \n",
       "9999995  2019043057226      OOLU8979700       7280342           NaN   \n",
       "9999996  2019043057226      OOLU9568200       7280341           NaN   \n",
       "9999997  2019043057227      OOLU7866680    OOLESU2963           NaN   \n",
       "9999998  2019043057227      OOLU7640434    OOLESU2955           NaN   \n",
       "9999999  2019043057228      KKTU8114548     TW070212A           NaN   \n",
       "\n",
       "                equipment_description_code  container_length  \\\n",
       "0                                Container              4000   \n",
       "1                                Container              2000   \n",
       "2                                Container              4000   \n",
       "3                                Container              4000   \n",
       "4                                Container              4000   \n",
       "...                                    ...               ...   \n",
       "9999995                                 G1              4000   \n",
       "9999996                                 G1              4000   \n",
       "9999997                                 G1              4000   \n",
       "9999998                                 G1              4000   \n",
       "9999999  Openings at one end or both ends.              2000   \n",
       "\n",
       "         container_height  container_width container_type load_status  \\\n",
       "0                     906              802           4EB0      Loaded   \n",
       "1                     806              800           2200      Loaded   \n",
       "2                     900              800           45G0      Loaded   \n",
       "3                     900              800           45G0      Loaded   \n",
       "4                     900              800           45G0      Loaded   \n",
       "...                   ...              ...            ...         ...   \n",
       "9999995               900              800           45G1      Loaded   \n",
       "9999996               900              800           45G1      Loaded   \n",
       "9999997               806              800           42G1      Loaded   \n",
       "9999998               806              800           42G1      Loaded   \n",
       "9999999               806              802           2CG0      Loaded   \n",
       "\n",
       "        type_of_service  \n",
       "0        Container Yard  \n",
       "1        Container Yard  \n",
       "2        Container Yard  \n",
       "3        Container Yard  \n",
       "4        Container Yard  \n",
       "...                 ...  \n",
       "9999995  House to House  \n",
       "9999996  House to House  \n",
       "9999997  House to House  \n",
       "9999998  House to House  \n",
       "9999999   Pier to House  \n",
       "\n",
       "[10000000 rows x 11 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currated layer only requires : container |  header  |  tariff   |   billgen   \n",
    "dfs = gen_dfs(path='container')\n",
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns we will not be using\n",
    "drop_dfs_col(dfs, rm_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes into one    30635677 rows Ã— 6 columns   27234627 rows Ã— 6 columns\n",
    "dfs = merge_dfs(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate records  \n",
    "rm_dupe(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifier : False\n",
      "container_number : False\n",
      "container_length : False\n",
      "container_height : False\n",
      "container_width : False\n",
      "type_of_service : False\n"
     ]
    }
   ],
   "source": [
    "# remove any null values\n",
    "for col in cols_with_null(dfs):\n",
    "    rm_nulls(dfs, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any invalid length in this col\n",
    "dfs = rm_inval_type(dfs, 'container_length', int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any invalid height in this col\n",
    "dfs = rm_inval_type(dfs, 'container_height', int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes any invalid width in this col\n",
    "dfs = rm_inval_type(dfs, 'container_width', int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = rm_box_outlier(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped_counts = dfs.groupby(['container_length', 'container_height', 'container_width']).size().reset_index(name='counts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>container_length</th>\n",
       "      <th>container_height</th>\n",
       "      <th>container_width</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>4300</td>\n",
       "      <td>405</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4800</td>\n",
       "      <td>906</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4300</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>4500</td>\n",
       "      <td>106</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4500</td>\n",
       "      <td>400</td>\n",
       "      <td>800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2000</td>\n",
       "      <td>806</td>\n",
       "      <td>802</td>\n",
       "      <td>1313479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4000</td>\n",
       "      <td>906</td>\n",
       "      <td>802</td>\n",
       "      <td>1966473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4000</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>2770236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2000</td>\n",
       "      <td>806</td>\n",
       "      <td>800</td>\n",
       "      <td>4284757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4000</td>\n",
       "      <td>900</td>\n",
       "      <td>800</td>\n",
       "      <td>12479998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    container_length  container_height  container_width    counts\n",
       "54              4300               405              800         1\n",
       "76              4800               906              800         1\n",
       "55              4300               806              800         1\n",
       "56              4500               106              800         1\n",
       "58              4500               400              800         1\n",
       "..               ...               ...              ...       ...\n",
       "17              2000               806              802   1313479\n",
       "49              4000               906              802   1966473\n",
       "43              4000               806              800   2770236\n",
       "16              2000               806              800   4284757\n",
       "46              4000               900              800  12479998\n",
       "\n",
       "[89 rows x 4 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grouped_counts.sort_values('counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>container_length</th>\n",
       "      <th>container_height</th>\n",
       "      <th>container_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25707759.000</td>\n",
       "      <td>25707759.000</td>\n",
       "      <td>25707759.000</td>\n",
       "      <td>25707759.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1719988920255.021</td>\n",
       "      <td>3575.997</td>\n",
       "      <td>867.265</td>\n",
       "      <td>800.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>685883612136.753</td>\n",
       "      <td>843.788</td>\n",
       "      <td>47.140</td>\n",
       "      <td>3.572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>201901010.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>9.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2019020618414.000</td>\n",
       "      <td>4000.000</td>\n",
       "      <td>806.000</td>\n",
       "      <td>800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019052750135.000</td>\n",
       "      <td>4000.000</td>\n",
       "      <td>900.000</td>\n",
       "      <td>800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2019090942334.500</td>\n",
       "      <td>4000.000</td>\n",
       "      <td>900.000</td>\n",
       "      <td>800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20191130100288.000</td>\n",
       "      <td>6200.000</td>\n",
       "      <td>2400.000</td>\n",
       "      <td>1306.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              identifier  container_length  container_height  container_width\n",
       "count       25707759.000      25707759.000      25707759.000     25707759.000\n",
       "mean   1719988920255.021          3575.997           867.265          800.423\n",
       "std     685883612136.753           843.788            47.140            3.572\n",
       "min        201901010.000             6.000             9.000            8.000\n",
       "25%    2019020618414.000          4000.000           806.000          800.000\n",
       "50%    2019052750135.000          4000.000           900.000          800.000\n",
       "75%    2019090942334.500          4000.000           900.000          800.000\n",
       "max   20191130100288.000          6200.000          2400.000         1306.000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2parquet(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to Export Modified Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Establish a connection to the MySQL database\n",
    "\n",
    "Returns: \n",
    "\"\"\"\n",
    "def link_db():\n",
    "    try:\n",
    "        return pymssql.connect(server='DESKTOP-N9SA336')\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = link_db()\n",
    "if conn:\n",
    "    cursor = conn.cursor() # Cursors are database level objects that let your query a database multiple times - Think of it as a pointer to a row\n",
    "    cursor.execute(\"SELECT * FROM INFORMATION_SCHEMA.TABLES\")\n",
    "    rows = cursor.fetchall()\n",
    "    [print(row) for row in rows]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
